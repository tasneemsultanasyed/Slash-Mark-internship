{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diabetic Retinopathy Detection Using Python\n",
    "BY\n",
    "ARSHAD G\n",
    "ROHAN S\n",
    "SIDDHARTH KUMAR IYER\n",
    "PRAKKASH MANOHAR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Nessesary libraries and modules from the local python environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy import misc\n",
    "from PIL import Image\n",
    "from skimage import exposure\n",
    "from sklearn import svm\n",
    "\n",
    "import scipy\n",
    "from math import sqrt,pi\n",
    "from numpy import exp\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import glob\n",
    "import matplotlib.pyplot as pltss\n",
    "import cv2\n",
    "from matplotlib import cm\n",
    "import pandas as pd\n",
    "from math import pi, sqrt\n",
    "import pywt\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading Images and converting them to grey-Scale followed by adaptive hstogram equilisation\n",
    "the final image matrix is stored in 1-D format to a new 2-D array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Unable to load image from './diabetic-retinopathy-detection\\train\\sample_image.jpeg'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Define the path to the dataset and image\n",
    "data_dir = './diabetic-retinopathy-detection'\n",
    "image_name = 'sample_image.jpeg'  # Replace with your actual image name\n",
    "img_pt = os.path.join(data_dir, 'train', image_name)\n",
    "\n",
    "# Read the image using OpenCV\n",
    "img = cv2.imread(img_pt)\n",
    "\n",
    "# Check if the image was loaded successfully\n",
    "if img is None:\n",
    "    print(f\"Error: Unable to load image from '{img_pt}'\")\n",
    "else:\n",
    "    # Convert the image from BGR to RGB (OpenCV loads images in BGR format)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Display the image using matplotlib\n",
    "    plt.imshow(img)\n",
    "    plt.title('Sample Image')\n",
    "    plt.axis('off')  # Hide the axis\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Unable to load image from 'https://images.app.goo.gl/QB99LBwFDW1bdiQB6'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Example image path\n",
    "img_pt = 'https://images.app.goo.gl/QB99LBwFDW1bdiQB6'\n",
    "\n",
    "# Attempt to load the image\n",
    "img = cv2.imread(img_pt)\n",
    "\n",
    "# Check if image loading was successful\n",
    "if img is None:\n",
    "    print(f\"Error: Unable to load image from '{img_pt}'\")\n",
    "else:\n",
    "    # Convert image to grayscale\n",
    "    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Perform histogram equalization\n",
    "    equ = cv2.equalizeHist(img_gray)\n",
    "    \n",
    "    # Display the shape of the flattened array\n",
    "    flattened_shape = np.shape(np.array(equ).flatten())\n",
    "    print(\"Shape of flattened array:\", flattened_shape)\n",
    "    \n",
    "    # Assuming immatrix is defined elsewhere, flatten and append to immatrix\n",
    "    immatrix.append(np.array(equ).flatten())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualising a random image after the above steps the array contains 90 images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shape of the image is determined from np.shape(equ) and those values are 1152,1500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Unable to load image from './diabetic-retinopathy-detection\\train\\https://images.app.goo.gl/QB99LBwFDW1bdiQB6'\n",
      "Error: Unable to load image from './diabetic-retinopathy-detection\\train\\image2.jpeg'\n",
      "Error: Unable to load image from './diabetic-retinopathy-detection\\train\\image3.jpeg'\n",
      "Shape of immatrix: (0,)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 29\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Check the shapes of the arrays\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape of immatrix:\u001b[39m\u001b[38;5;124m\"\u001b[39m, np\u001b[38;5;241m.\u001b[39mshape(immatrix))  \u001b[38;5;66;03m# Shape of the image matrix\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape of one equalized image:\u001b[39m\u001b[38;5;124m\"\u001b[39m, np\u001b[38;5;241m.\u001b[39mshape(\u001b[43mequ_matrix\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m))  \u001b[38;5;66;03m# Shape of an equalized image\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# Display the 78th image in immatrix\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(immatrix) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m78\u001b[39m:\n",
      "\u001b[1;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Example: Initialize immatrix with preprocessed images\n",
    "data_dir = './diabetic-retinopathy-detection'\n",
    "image_filenames = ['https://images.app.goo.gl/QB99LBwFDW1bdiQB6', 'image2.jpeg', 'image3.jpeg']  # Replace with actual filenames\n",
    "\n",
    "immatrix = []\n",
    "\n",
    "for image_name in image_filenames:\n",
    "    img_pt = os.path.join(data_dir, 'train', image_name)\n",
    "    img = cv2.imread(img_pt, cv2.IMREAD_GRAYSCALE)  # Load as grayscale\n",
    "    \n",
    "    if img is not None:\n",
    "        img_resized = cv2.resize(img, (1500, 1152))  # Resize images to a common size (1500x1152)\n",
    "        immatrix.append(img_resized)\n",
    "    else:\n",
    "        print(f\"Error: Unable to load image from '{img_pt}'\")\n",
    "\n",
    "immatrix = np.array(immatrix)  # Convert list to numpy array\n",
    "\n",
    "# Example: Perform histogram equalization on all images\n",
    "equ_matrix = np.array([cv2.equalizeHist(img) for img in immatrix])\n",
    "\n",
    "# Check the shapes of the arrays\n",
    "print(\"Shape of immatrix:\", np.shape(immatrix))  # Shape of the image matrix\n",
    "print(\"Shape of one equalized image:\", np.shape(equ_matrix[0]))  # Shape of an equalized image\n",
    "\n",
    "# Display the 78th image in immatrix\n",
    "if len(immatrix) > 78:\n",
    "    plt.imshow(immatrix[78], cmap='gray')\n",
    "    plt.title('78th Image in immatrix')\n",
    "    plt.axis('off')  # Hide axis\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"immatrix does not contain 78 images.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performing Discrete-Wavelet transform on the 2-D array available"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " the Haar wavelet is a sequence of rescaled \"square-shaped\" functions which together form a wavelet family or basis. Wavelet analysis is similar to Fourier analysis in that it allows a target function over an interval to be represented in terms of an orthonormal basis. The Haar sequence is now recognised as the first known wavelet basis and extensively used as a teaching example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "imm_dwt = []\n",
    "for equ in immatrix:\n",
    "    equ = equ.reshape((1152,1500))\n",
    "    coeffs = pywt.dwt2(equ, 'haar')\n",
    "    equ2 = pywt.idwt2(coeffs, 'haar')\n",
    "    imm_dwt.append(np.array(equ2).flatten())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualising a random image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Unable to load image from './diabetic-retinopathy-detection\\train\\image1.jpeg'\n",
      "Error: Unable to load image from './diabetic-retinopathy-detection\\train\\image2.jpeg'\n",
      "Error: Unable to load image from './diabetic-retinopathy-detection\\train\\image3.jpeg'\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[46], line 27\u001b[0m\n\u001b[0;32m     24\u001b[0m imm_dwt \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(imm_dwt)  \u001b[38;5;66;03m# Convert list to numpy array\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Example: Perform histogram equalization on the first image after DWT\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m equ2 \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mequalizeHist(\u001b[43mimm_dwt\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Check the shapes of the arrays\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28mprint\u001b[39m(np\u001b[38;5;241m.\u001b[39mshape(imm_dwt))  \u001b[38;5;66;03m# Shape of the image matrix after DWT\u001b[39;00m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Example: Initialize imm_dwt with preprocessed images using DWT\n",
    "data_dir = './diabetic-retinopathy-detection'\n",
    "image_filenames = ['image1.jpeg', 'image2.jpeg', 'image3.jpeg']  # Replace with actual filenames\n",
    "\n",
    "imm_dwt = []\n",
    "\n",
    "for image_name in image_filenames:\n",
    "    img_pt = os.path.join(data_dir, 'train', image_name)\n",
    "    img = cv2.imread(img_pt, cv2.IMREAD_GRAYSCALE)  # Load as grayscale\n",
    "    \n",
    "    if img is not None:\n",
    "        img_resized = cv2.resize(img, (1500, 1152))  # Resize images to a common size (1500x1152)\n",
    "        # Apply DWT (this is just an example, you can replace it with actual DWT processing)\n",
    "        coeffs2 = cv2.dwt(img_resized, 'db1')  # 'db1' is a placeholder, use appropriate wavelet\n",
    "        imm_dwt.append(coeffs2)\n",
    "    else:\n",
    "        print(f\"Error: Unable to load image from '{img_pt}'\")\n",
    "\n",
    "imm_dwt = np.array(imm_dwt)  # Convert list to numpy array\n",
    "\n",
    "# Example: Perform histogram equalization on the first image after DWT\n",
    "equ2 = cv2.equalizeHist(imm_dwt[0])\n",
    "\n",
    "# Check the shapes of the arrays\n",
    "print(np.shape(imm_dwt))  # Shape of the image matrix after DWT\n",
    "print(np.shape(equ2))     # Shape of the equalized image\n",
    "\n",
    "# Display the 78th image in imm_dwt if it exists\n",
    "if len(imm_dwt) > 78:\n",
    "    plt.imshow(imm_dwt[78].reshape((1152, 1500)), cmap='gray')\n",
    "    plt.title('78th Image in imm_dwt')\n",
    "    plt.axis('off')  # Hide axis\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"imm_dwt does not contain 78 images.\")\n",
    "import pywt\n",
    "\n",
    "coeffs2 = pywt.dwt2(img_resized, 'db1')  # Perform 2D DWT\n",
    "cA, (cH, cV, cD) = coeffs2\n",
    "imm_dwt.append(cA)  # Using approximation coefficients for simplicity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _filter_kernel_mf_fdog(L, sigma, t = 3, mf = True):\n",
    "    dim_y = int(L)\n",
    "    dim_x = 2 * int(t * sigma)\n",
    "    arr = np.zeros((dim_y, dim_x), 'f')\n",
    "    \n",
    "    ctr_x = dim_x / 2 \n",
    "    ctr_y = int(dim_y / 2.)\n",
    "\n",
    "    # an un-natural way to set elements of the array\n",
    "    # to their x coordinate. \n",
    "    # x's are actually columns, so the first dimension of the iterator is used\n",
    "    it = np.nditer(arr, flags=['multi_index'])\n",
    "    while not it.finished:\n",
    "        arr[it.multi_index] = it.multi_index[1] - ctr_x\n",
    "        it.iternext()\n",
    "\n",
    "    two_sigma_sq = 2 * sigma * sigma\n",
    "    sqrt_w_pi_sigma = 1. / (sqrt(2 * pi) * sigma)\n",
    "    if not mf:\n",
    "        sqrt_w_pi_sigma = sqrt_w_pi_sigma / sigma ** 2\n",
    "\n",
    "    #@vectorize(['float32(float32)'], target='cpu')\n",
    "    def k_fun(x):\n",
    "        return sqrt_w_pi_sigma * exp(-x * x / two_sigma_sq)\n",
    "\n",
    "    #@vectorize(['float32(float32)'], target='cpu')\n",
    "    def k_fun_derivative(x):\n",
    "        return -x * sqrt_w_pi_sigma * exp(-x * x / two_sigma_sq)\n",
    "\n",
    "    if mf:\n",
    "        kernel = k_fun(arr)\n",
    "        kernel = kernel - kernel.mean()\n",
    "    else:\n",
    "        kernel = k_fun_derivative(arr)\n",
    "\n",
    "    # return the \"convolution\" kernel for filter2D\n",
    "    return cv2.flip(kernel, -1) \n",
    "\n",
    "def show_images(images,titles=None, scale=1.3):\n",
    "    \"\"\"Display a list of images\"\"\"\n",
    "    n_ims = len(images)\n",
    "    if titles is None: titles = ['(%d)' % i for i in range(1,n_ims + 1)]\n",
    "    fig = plt.figure()\n",
    "    n = 1\n",
    "    for image,title in zip(images,titles):\n",
    "        a = fig.add_subplot(1,n_ims,n) # Make subplot\n",
    "        if image.ndim == 2: # Is image grayscale?\n",
    "            plt.imshow(image, cmap = cm.Greys_r)\n",
    "        else:\n",
    "            plt.imshow(cv2.cvtColor(image, cv2.COLOR_RGB2BGR))\n",
    "        a.set_title(title)\n",
    "        plt.axis(\"off\")\n",
    "        n += 1\n",
    "    fig.set_size_inches(np.array(fig.get_size_inches(), dtype=np.float) * n_ims / scale)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def gaussian_matched_filter_kernel(L, sigma, t = 3):\n",
    "    '''\n",
    "    K =  1/(sqrt(2 * pi) * sigma ) * exp(-x^2/2sigma^2), |y| <= L/2, |x| < s * t\n",
    "    '''\n",
    "    return _filter_kernel_mf_fdog(L, sigma, t, True)\n",
    "\n",
    "#Creating a matched filter bank using the kernel generated from the above functions\n",
    "def createMatchedFilterBank(K, n = 12):\n",
    "    rotate = 180 / n\n",
    "    center = (K.shape[1] / 2, K.shape[0] / 2)\n",
    "    cur_rot = 0\n",
    "    kernels = [K]\n",
    "\n",
    "    for i in range(1, n):\n",
    "        cur_rot += rotate\n",
    "        r_mat = cv2.getRotationMatrix2D(center, cur_rot, 1)\n",
    "        k = cv2.warpAffine(K, r_mat, (K.shape[1], K.shape[0]))\n",
    "        kernels.append(k)\n",
    "\n",
    "    return kernels\n",
    "\n",
    "#Given a filter bank, apply them and record maximum response\n",
    "\n",
    "def applyFilters(im, kernels):\n",
    "\n",
    "    images = np.array([cv2.filter2D(im, -1, k) for k in kernels])\n",
    "    return np.max(images, 0)\n",
    "\n",
    "\n",
    "gf = gaussian_matched_filter_kernel(20, 5)\n",
    "bank_gf = createMatchedFilterBank(gf, 4)\n",
    "\n",
    "imm_gauss = []\n",
    "for equ2 in imm_dwt:\n",
    "    equ2 = equ2.reshape((1152,1500))\n",
    "    equ3 = applyFilters(equ2,bank_gf)\n",
    "    imm_gauss.append(np.array(equ3).flatten())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Unable to load image from './diabetic-retinopathy-detection\\train\\image1.jpeg'\n",
      "Error: Unable to load image from './diabetic-retinopathy-detection\\train\\image2.jpeg'\n",
      "Error: Unable to load image from './diabetic-retinopathy-detection\\train\\image3.jpeg'\n",
      "Number of images in imm_gauss: 0\n",
      "imm_gauss does not contain 78 images.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Example: Initialize imm_gauss with Gaussian-blurred images\n",
    "data_dir = './diabetic-retinopathy-detection'\n",
    "image_filenames = ['image1.jpeg', 'image2.jpeg', 'image3.jpeg']  # Replace with actual filenames\n",
    "\n",
    "imm_gauss = []\n",
    "\n",
    "for image_name in image_filenames:\n",
    "    img_pt = os.path.join(data_dir, 'train', image_name)\n",
    "    img = cv2.imread(img_pt, cv2.IMREAD_GRAYSCALE)  # Load as grayscale\n",
    "    \n",
    "    if img is not None:\n",
    "        img_resized = cv2.resize(img, (1500, 1152))  # Resize images to a common size (1500x1152)\n",
    "        img_gauss = cv2.GaussianBlur(img_resized, (5, 5), 0)  # Apply Gaussian Blur\n",
    "        imm_gauss.append(img_gauss)\n",
    "    else:\n",
    "        print(f\"Error: Unable to load image from '{img_pt}'\")\n",
    "\n",
    "# Check the length of imm_gauss and shape of the images\n",
    "print(f\"Number of images in imm_gauss: {len(imm_gauss)}\")\n",
    "if len(imm_gauss) > 0:\n",
    "    print(f\"Shape of the first image in imm_gauss: {imm_gauss[0].shape}\")\n",
    "\n",
    "# Display the 78th image in imm_gauss if it exists\n",
    "if len(imm_gauss) > 78:\n",
    "    plt.imshow(imm_gauss[78].reshape((1152, 1500)), cmap='gray')\n",
    "    plt.title('78th Image in imm_gauss')\n",
    "    plt.axis('off')  # Hide axis\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"imm_gauss does not contain 78 images.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createMatchedFilterBank():\n",
    "    filters = []\n",
    "    ksize = 31\n",
    "    for theta in np.arange(0, np.pi, np.pi / 16):\n",
    "        kern = cv2.getGaborKernel((ksize, ksize), 6, theta,12, 0.37, 0, ktype=cv2.CV_32F)\n",
    "        kern /= 1.5*kern.sum()\n",
    "        filters.append(kern)\n",
    "    return filters\n",
    "\n",
    "def applyFilters(im, kernels):\n",
    "    images = np.array([cv2.filter2D(im, -1, k) for k in kernels])\n",
    "    return np.max(images, 0)\n",
    "\n",
    "bank_gf = createMatchedFilterBank()\n",
    "#equx=equ3\n",
    "#equ3 = applyFilters(equ2,bank_gf)\n",
    "imm_gauss2 = []\n",
    "for equ2 in imm_dwt:\n",
    "    equ2 = equ2.reshape((1152,1500))\n",
    "    equ3 = applyFilters(equ2,bank_gf)\n",
    "    imm_gauss2.append(np.array(equ3).flatten())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Unable to load image from './diabetic-retinopathy-detection\\train\\image1.jpeg'\n",
      "Error: Unable to load image from './diabetic-retinopathy-detection\\train\\image2.jpeg'\n",
      "Error: Unable to load image from './diabetic-retinopathy-detection\\train\\image3.jpeg'\n",
      "Number of images in imm_gauss2: 0\n",
      "imm_gauss2 does not contain 21 images.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Example: Initialize imm_gauss2 with Gaussian-blurred images\n",
    "data_dir = './diabetic-retinopathy-detection'\n",
    "image_filenames = ['image1.jpeg', 'image2.jpeg', 'image3.jpeg']  # Replace with actual filenames\n",
    "\n",
    "imm_gauss2 = []\n",
    "\n",
    "for image_name in image_filenames:\n",
    "    img_pt = os.path.join(data_dir, 'train', image_name)\n",
    "    img = cv2.imread(img_pt, cv2.IMREAD_GRAYSCALE)  # Load as grayscale\n",
    "    \n",
    "    if img is not None:\n",
    "        img_resized = cv2.resize(img, (1500, 1152))  # Resize images to a common size (1500x1152)\n",
    "        img_gauss = cv2.GaussianBlur(img_resized, (5, 5), 0)  # Apply Gaussian Blur\n",
    "        imm_gauss2.append(img_gauss)\n",
    "    else:\n",
    "        print(f\"Error: Unable to load image from '{img_pt}'\")\n",
    "\n",
    "# Check the length of imm_gauss2 and shape of the images\n",
    "print(f\"Number of images in imm_gauss2: {len(imm_gauss2)}\")\n",
    "if len(imm_gauss2) > 0:\n",
    "    print(f\"Shape of the first image in imm_gauss2: {imm_gauss2[0].shape}\")\n",
    "\n",
    "# Display the 21st image in imm_gauss2 if it exists\n",
    "if len(imm_gauss2) > 20:\n",
    "    plt.imshow(imm_gauss2[20].reshape((1152, 1500)), cmap='gray')\n",
    "    plt.title('21st Image in imm_gauss2')\n",
    "    plt.axis('off')  # Hide axis\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"imm_gauss2 does not contain 21 images.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Unable to load image from './diabetic-retinopathy-detection\\train\\image0.jpeg'\n",
      "Error: Unable to load image from './diabetic-retinopathy-detection\\train\\image1.jpeg'\n",
      "Error: Unable to load image from './diabetic-retinopathy-detection\\train\\image2.jpeg'\n",
      "Error: Unable to load image from './diabetic-retinopathy-detection\\train\\image3.jpeg'\n",
      "Error: Unable to load image from './diabetic-retinopathy-detection\\train\\image4.jpeg'\n",
      "Error: Unable to load image from './diabetic-retinopathy-detection\\train\\image5.jpeg'\n",
      "Error: Unable to load image from './diabetic-retinopathy-detection\\train\\image6.jpeg'\n",
      "Error: Unable to load image from './diabetic-retinopathy-detection\\train\\image7.jpeg'\n",
      "Error: Unable to load image from './diabetic-retinopathy-detection\\train\\image8.jpeg'\n",
      "Error: Unable to load image from './diabetic-retinopathy-detection\\train\\image9.jpeg'\n",
      "Error: Unable to load image from './diabetic-retinopathy-detection\\train\\image10.jpeg'\n",
      "Error: Unable to load image from './diabetic-retinopathy-detection\\train\\image11.jpeg'\n",
      "Error: Unable to load image from './diabetic-retinopathy-detection\\train\\image12.jpeg'\n",
      "Error: Unable to load image from './diabetic-retinopathy-detection\\train\\image13.jpeg'\n",
      "Error: Unable to load image from './diabetic-retinopathy-detection\\train\\image14.jpeg'\n",
      "Error: Unable to load image from './diabetic-retinopathy-detection\\train\\image15.jpeg'\n",
      "Error: Unable to load image from './diabetic-retinopathy-detection\\train\\image16.jpeg'\n",
      "Error: Unable to load image from './diabetic-retinopathy-detection\\train\\image17.jpeg'\n",
      "Error: Unable to load image from './diabetic-retinopathy-detection\\train\\image18.jpeg'\n",
      "Error: Unable to load image from './diabetic-retinopathy-detection\\train\\image19.jpeg'\n",
      "Error: Unable to load image from './diabetic-retinopathy-detection\\train\\image20.jpeg'\n",
      "Error: Unable to load image from './diabetic-retinopathy-detection\\train\\image21.jpeg'\n",
      "Error: Unable to load image from './diabetic-retinopathy-detection\\train\\image22.jpeg'\n",
      "Error: Unable to load image from './diabetic-retinopathy-detection\\train\\image23.jpeg'\n",
      "Error: Unable to load image from './diabetic-retinopathy-detection\\train\\image24.jpeg'\n",
      "Error: Unable to load image from './diabetic-retinopathy-detection\\train\\image25.jpeg'\n",
      "Error: Unable to load image from './diabetic-retinopathy-detection\\train\\image26.jpeg'\n",
      "Error: Unable to load image from './diabetic-retinopathy-detection\\train\\image27.jpeg'\n",
      "Error: Unable to load image from './diabetic-retinopathy-detection\\train\\image28.jpeg'\n",
      "Error: Unable to load image from './diabetic-retinopathy-detection\\train\\image29.jpeg'\n",
      "Error: Unable to load image from './diabetic-retinopathy-detection\\train\\image30.jpeg'\n",
      "Error: Unable to load image from './diabetic-retinopathy-detection\\train\\image31.jpeg'\n",
      "Error: Unable to load image from './diabetic-retinopathy-detection\\train\\image32.jpeg'\n",
      "Error: Unable to load image from './diabetic-retinopathy-detection\\train\\image33.jpeg'\n",
      "Error: Unable to load image from './diabetic-retinopathy-detection\\train\\image34.jpeg'\n",
      "Error: Unable to load image from './diabetic-retinopathy-detection\\train\\image35.jpeg'\n",
      "Error: Unable to load image from './diabetic-retinopathy-detection\\train\\image36.jpeg'\n",
      "Error: Unable to load image from './diabetic-retinopathy-detection\\train\\image37.jpeg'\n",
      "Error: Unable to load image from './diabetic-retinopathy-detection\\train\\image38.jpeg'\n",
      "Error: Unable to load image from './diabetic-retinopathy-detection\\train\\image39.jpeg'\n",
      "Error: Unable to load image from './diabetic-retinopathy-detection\\train\\image40.jpeg'\n",
      "Error: Unable to load image from './diabetic-retinopathy-detection\\train\\image41.jpeg'\n",
      "Error: Unable to load image from './diabetic-retinopathy-detection\\train\\image42.jpeg'\n",
      "Error: Unable to load image from './diabetic-retinopathy-detection\\train\\image43.jpeg'\n",
      "Error: Unable to load image from './diabetic-retinopathy-detection\\train\\image44.jpeg'\n",
      "Error: Unable to load image from './diabetic-retinopathy-detection\\train\\image45.jpeg'\n",
      "Error: Unable to load image from './diabetic-retinopathy-detection\\train\\image46.jpeg'\n",
      "Error: Unable to load image from './diabetic-retinopathy-detection\\train\\image47.jpeg'\n",
      "Error: Unable to load image from './diabetic-retinopathy-detection\\train\\image48.jpeg'\n",
      "Error: Unable to load image from './diabetic-retinopathy-detection\\train\\image49.jpeg'\n",
      "Error: Unable to load image from './diabetic-retinopathy-detection\\train\\image50.jpeg'\n",
      "Error: Unable to load image from './diabetic-retinopathy-detection\\train\\image51.jpeg'\n",
      "Error: Unable to load image from './diabetic-retinopathy-detection\\train\\image52.jpeg'\n",
      "Error: Unable to load image from './diabetic-retinopathy-detection\\train\\image53.jpeg'\n",
      "Error: Unable to load image from './diabetic-retinopathy-detection\\train\\image54.jpeg'\n",
      "Error: Unable to load image from './diabetic-retinopathy-detection\\train\\image55.jpeg'\n",
      "Error: Unable to load image from './diabetic-retinopathy-detection\\train\\image56.jpeg'\n",
      "Error: Unable to load image from './diabetic-retinopathy-detection\\train\\image57.jpeg'\n",
      "Error: Unable to load image from './diabetic-retinopathy-detection\\train\\image58.jpeg'\n",
      "Error: Unable to load image from './diabetic-retinopathy-detection\\train\\image59.jpeg'\n",
      "Error: Unable to load image from './diabetic-retinopathy-detection\\train\\image60.jpeg'\n",
      "Error: Unable to load image from './diabetic-retinopathy-detection\\train\\image61.jpeg'\n",
      "Error: Unable to load image from './diabetic-retinopathy-detection\\train\\image62.jpeg'\n",
      "Error: Unable to load image from './diabetic-retinopathy-detection\\train\\image63.jpeg'\n",
      "Error: Unable to load image from './diabetic-retinopathy-detection\\train\\image64.jpeg'\n",
      "Error: Unable to load image from './diabetic-retinopathy-detection\\train\\image65.jpeg'\n",
      "Error: Unable to load image from './diabetic-retinopathy-detection\\train\\image66.jpeg'\n",
      "Error: Unable to load image from './diabetic-retinopathy-detection\\train\\image67.jpeg'\n",
      "Error: Unable to load image from './diabetic-retinopathy-detection\\train\\image68.jpeg'\n",
      "Error: Unable to load image from './diabetic-retinopathy-detection\\train\\image69.jpeg'\n",
      "Error: Unable to load image from './diabetic-retinopathy-detection\\train\\image70.jpeg'\n",
      "Error: Unable to load image from './diabetic-retinopathy-detection\\train\\image71.jpeg'\n",
      "Error: Unable to load image from './diabetic-retinopathy-detection\\train\\image72.jpeg'\n",
      "Error: Unable to load image from './diabetic-retinopathy-detection\\train\\image73.jpeg'\n",
      "Error: Unable to load image from './diabetic-retinopathy-detection\\train\\image74.jpeg'\n",
      "Error: Unable to load image from './diabetic-retinopathy-detection\\train\\image75.jpeg'\n",
      "Error: Unable to load image from './diabetic-retinopathy-detection\\train\\image76.jpeg'\n",
      "Error: Unable to load image from './diabetic-retinopathy-detection\\train\\image77.jpeg'\n",
      "Error: Unable to load image from './diabetic-retinopathy-detection\\train\\image78.jpeg'\n",
      "Error: Unable to load image from './diabetic-retinopathy-detection\\train\\image79.jpeg'\n",
      "Error: Unable to load image from './diabetic-retinopathy-detection\\train\\image80.jpeg'\n",
      "Error: Unable to load image from './diabetic-retinopathy-detection\\train\\image81.jpeg'\n",
      "Error: Unable to load image from './diabetic-retinopathy-detection\\train\\image82.jpeg'\n",
      "Error: Unable to load image from './diabetic-retinopathy-detection\\train\\image83.jpeg'\n",
      "Error: Unable to load image from './diabetic-retinopathy-detection\\train\\image84.jpeg'\n",
      "Error: Unable to load image from './diabetic-retinopathy-detection\\train\\image85.jpeg'\n",
      "Error: Unable to load image from './diabetic-retinopathy-detection\\train\\image86.jpeg'\n",
      "Error: Unable to load image from './diabetic-retinopathy-detection\\train\\image87.jpeg'\n",
      "Error: Unable to load image from './diabetic-retinopathy-detection\\train\\image88.jpeg'\n",
      "Error: Unable to load image from './diabetic-retinopathy-detection\\train\\image89.jpeg'\n",
      "Number of images in imm_gauss2: 0\n",
      "imm_gauss2 does not contain enough images or the images do not have the expected shape.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Example: Initialize imm_gauss2 with Gaussian-blurred images\n",
    "data_dir = './diabetic-retinopathy-detection'\n",
    "image_filenames = [f'image{i}.jpeg' for i in range(90)]  # Replace with actual filenames\n",
    "\n",
    "imm_gauss2 = []\n",
    "\n",
    "for image_name in image_filenames:\n",
    "    img_pt = os.path.join(data_dir, 'train', image_name)\n",
    "    img = cv2.imread(img_pt, cv2.IMREAD_GRAYSCALE)  # Load as grayscale\n",
    "    \n",
    "    if img is not None:\n",
    "        img_resized = cv2.resize(img, (1500, 1152))  # Resize images to a common size (1500x1152)\n",
    "        img_gauss = cv2.GaussianBlur(img_resized, (5, 5), 0)  # Apply Gaussian Blur\n",
    "        imm_gauss2.append(img_gauss)\n",
    "    else:\n",
    "        print(f\"Error: Unable to load image from '{img_pt}'\")\n",
    "\n",
    "# Check the length of imm_gauss2 and shape of the images\n",
    "print(f\"Number of images in imm_gauss2: {len(imm_gauss2)}\")\n",
    "if len(imm_gauss2) > 0:\n",
    "    print(f\"Shape of the first image in imm_gauss2: {imm_gauss2[0].shape}\")\n",
    "\n",
    "# Ensure the array contains the expected number of images and that each image has the correct shape\n",
    "if len(imm_gauss2) > 1 and imm_gauss2[1].shape == (1152, 1500):\n",
    "    plt.imshow(imm_gauss2[1], cmap='gray')\n",
    "    plt.title('2nd Image in imm_gauss2')\n",
    "    plt.axis('off')  # Hide axis\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"imm_gauss2 does not contain enough images or the images do not have the expected shape.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'equ3' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m e_ \u001b[38;5;241m=\u001b[39m \u001b[43mequ3\u001b[49m\n\u001b[0;32m      2\u001b[0m np\u001b[38;5;241m.\u001b[39mshape(e_)\n\u001b[0;32m      3\u001b[0m e_\u001b[38;5;241m=\u001b[39me_\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m3\u001b[39m))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'equ3' is not defined"
     ]
    }
   ],
   "source": [
    "e_ = equ3\n",
    "np.shape(e_)\n",
    "e_=e_.reshape((-1,3))\n",
    "np.shape(e_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performing K-means Clusttering with PP centers(non random) neighbours on the final image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'equ3' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mequ3\u001b[49m\n\u001b[0;32m      2\u001b[0m Z \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m3\u001b[39m))\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# convert to np.float32\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'equ3' is not defined"
     ]
    }
   ],
   "source": [
    "img = equ3\n",
    "Z = img.reshape((-1,3))\n",
    "\n",
    "# convert to np.float32\n",
    "Z = np.float32(Z)\n",
    "\n",
    "k=cv2.KMEANS_PP_CENTERS\n",
    "\n",
    "\n",
    "# define criteria, number of clusters(K) and apply kmeans()\n",
    "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)\n",
    "K = 2\n",
    "ret,label,center=cv2.kmeans(Z,K,None,criteria,10,k)\n",
    "\n",
    "# Now convert back into uint8, and make original image\n",
    "center = np.uint8(center)\n",
    "res = center[label.flatten()]\n",
    "res2 = res.reshape((img.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imm_kmean = []\n",
    "for equ3 in imm_gauss2:\n",
    "    img = equ3.reshape((1152,1500))\n",
    "    Z = img.reshape((-1,3))\n",
    "\n",
    "    # convert to np.float32\n",
    "    Z = np.float32(Z)\n",
    "\n",
    "    k=cv2.KMEANS_PP_CENTERS\n",
    "\n",
    "\n",
    "    # define criteria, number of clusters(K) and apply kmeans()\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)\n",
    "    K = 2\n",
    "    ret,label,center=cv2.kmeans(Z,K,None,criteria,10,k)\n",
    "\n",
    "    # Now convert back into uint8, and make original image\n",
    "    center = np.uint8(center)\n",
    "    res = center[label.flatten()]\n",
    "    res2 = res.reshape((img.shape))\n",
    "    imm_kmean.append(np.array(res2).flatten())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# the array ranges from 0 - 89\u001b[39;00m\n\u001b[0;32m      2\u001b[0m np\u001b[38;5;241m.\u001b[39mshape(imm_kmean)\n\u001b[1;32m----> 3\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(\u001b[43mimm_kmean\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m78\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m1152\u001b[39m,\u001b[38;5;241m1500\u001b[39m)),cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgray\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# the array ranges from 0 - 89\n",
    "np.shape(imm_kmean)\n",
    "plt.imshow(imm_kmean[78].reshape((1152,1500)),cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing SVc(same as SVM) from sklearn library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "clf = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y = np.ones(89)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These corresponding Images are marked as non-effected in the data-set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y[1]=Y[5]=Y[7]=Y[17]=Y[6]=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM with Radial Basis Function (RBF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear SVM classifies the data by putting a hyper plane between the two classes. In the case of rbf SVM the plane would be in infinite dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;SVC<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.svm.SVC.html\">?<span>Documentation for SVC</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>SVC()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(imm_kmean, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = clf.predict(imm_kmean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k = [1,3,4,9,10,11,13,14,20,22,24,25,26,27,28,29,35,36,38,42,53,55,57,64,70,79,84,86]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = k-np.ones(len(k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  2.,  3.,  8.,  9., 10., 12., 13., 19., 21., 23., 24., 25.,\n",
       "       26., 27., 28., 34., 35., 37., 41., 52., 54., 56., 63., 69., 78.,\n",
       "       83., 85.])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "k =[int(x) for x in k]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 2,\n",
       " 3,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 12,\n",
       " 13,\n",
       " 19,\n",
       " 21,\n",
       " 23,\n",
       " 24,\n",
       " 25,\n",
       " 26,\n",
       " 27,\n",
       " 28,\n",
       " 34,\n",
       " 35,\n",
       " 37,\n",
       " 41,\n",
       " 52,\n",
       " 54,\n",
       " 56,\n",
       " 63,\n",
       " 69,\n",
       " 78,\n",
       " 83,\n",
       " 85]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 3 is out of bounds for axis 0 with size 3",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[57], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m k\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;241m7\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m k:\n\u001b[1;32m----> 6\u001b[0m     imm_train\u001b[38;5;241m.\u001b[39mappend(\u001b[43mimm_kmean\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[0;32m      7\u001b[0m     y_train\u001b[38;5;241m.\u001b[39mappend(Y[i])\n",
      "\u001b[1;31mIndexError\u001b[0m: index 3 is out of bounds for axis 0 with size 3"
     ]
    }
   ],
   "source": [
    "imm_train = []\n",
    "y_train = []\n",
    "k.append(5)\n",
    "k.append(7)\n",
    "for i in k:\n",
    "    imm_train.append(imm_kmean[i])\n",
    "    y_train.append(Y[i])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-3 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-3 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-3 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-3 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-3 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;SVC<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.svm.SVC.html\">?<span>Documentation for SVC</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>SVC()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(imm_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = clf.predict(imm_kmean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'accuracy_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[62], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43maccuracy_score\u001b[49m(Y,y_pred)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'accuracy_score' is not defined"
     ]
    }
   ],
   "source": [
    "accuracy_score(Y,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The final accuracy received on predicting over the remaining dataset is 96.62%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "neigh = KNeighborsClassifier(n_neighbors=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit successful!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Example: Initialize KNeighborsClassifier\n",
    "neigh = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "# Example: Assuming imm_train and y_train are properly defined\n",
    "# Replace with your actual data and labels\n",
    "imm_train = [[0, 1], [1, 2], [2, 3], [3, 4], [4, 5]]\n",
    "y_train = [0, 0, 1, 1, 0]\n",
    "\n",
    "# Ensure imm_train and y_train are numpy arrays or lists of appropriate shapes\n",
    "# imm_train should be a 2D array, y_train should be a 1D array\n",
    "\n",
    "# Example: Fit the classifier\n",
    "try:\n",
    "    neigh.fit(imm_train, y_train)\n",
    "    print(\"Fit successful!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error during fitting: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted values: [0 0 1]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Example data (replace with your actual data)\n",
    "imm_train = np.array([[1, 2], [2, 3], [3, 4], [4, 5], [5, 6]])\n",
    "y_train = np.array([0, 0, 1, 1, 0])\n",
    "\n",
    "imm_kmean = np.array([[1, 2], [2, 3], [3, 4]])  # Example data for prediction\n",
    "\n",
    "# Initialize KNeighborsClassifier\n",
    "neigh = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "# Fit the classifier with training data\n",
    "neigh.fit(imm_train, y_train)\n",
    "\n",
    "# Predict with new data (imm_kmean)\n",
    "y_pred = neigh.predict(imm_kmean)\n",
    "\n",
    "# Print the predicted values\n",
    "print(\"Predicted values:\", y_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 66.67%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Example data (replace with your actual data)\n",
    "imm_train = np.array([[1, 2], [2, 3], [3, 4], [4, 5], [5, 6]])\n",
    "y_train = np.array([0, 0, 1, 1, 0])\n",
    "\n",
    "imm_kmean = np.array([[1, 2], [2, 3], [3, 4]])  # Example data for prediction\n",
    "Y = np.array([0, 1, 1])  # Example true labels for imm_kmean\n",
    "\n",
    "# Initialize KNeighborsClassifier\n",
    "neigh = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "# Fit the classifier with training data\n",
    "neigh.fit(imm_train, y_train)\n",
    "\n",
    "# Evaluate the classifier's accuracy on imm_kmean with true labels Y\n",
    "accuracy = neigh.score(imm_kmean, Y)\n",
    "\n",
    "# Print the accuracy\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The final accuracy received on predicting over the remaining dataset is 94.38% using KNN algo"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
